name: Core CI (Strict)

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      debug:
        description: 'Debug mode'
        required: false
        default: 'false'

jobs:
  build-strict:
    name: Strict Build (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]

    env:
      FIELD_COMPARE_RTOL: 1e-6

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Cache vcpkg packages
        uses: actions/cache@v3
        with:
          path: |
            C:\vcpkg\installed
            C:\vcpkg\packages
            ~/vcpkg/installed
            ~/vcpkg/packages
            ~/.cache/vcpkg
            ~/AppData/Local/vcpkg/archives
          key: ${{ runner.os }}-vcpkg-${{ hashFiles('**/vcpkg.json') }}-v2
          restore-keys: |
            ${{ runner.os }}-vcpkg-
            
      - name: Setup MSYS2 (Windows)
        if: runner.os == 'Windows'
        uses: msys2/setup-msys2@v2
        with:
          update: true
          install: >-
            mingw-w64-x86_64-gcc
            mingw-w64-x86_64-cmake
            mingw-w64-x86_64-ninja
            mingw-w64-x86_64-pkg-config

      - name: Setup vcpkg
        shell: bash
        run: |
          if [ ! -d "vcpkg" ]; then
            git clone https://github.com/microsoft/vcpkg.git vcpkg
            if [ "$RUNNER_OS" = "Windows" ]; then
              ./vcpkg/bootstrap-vcpkg.bat
            else
              ./vcpkg/bootstrap-vcpkg.sh
            fi
          fi
          echo "VCPKG_ROOT=$(pwd)/vcpkg" >> $GITHUB_ENV

      - name: Install dependencies (Linux)
        if: runner.os == 'Linux'
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential cmake ninja-build pkg-config

      - name: Install dependencies (macOS)
        if: runner.os == 'macOS'
        run: |
          brew install cmake ninja pkg-config

      - name: Install dependencies (Windows)
        if: runner.os == 'Windows'
        shell: msys2 {0}
        run: |
          echo "Windows dependencies already installed via MSYS2"

      - name: Configure
        shell: bash
        run: |
          cmake -S . -B build \
            -DCMAKE_BUILD_TYPE=Release \
            -DCMAKE_TOOLCHAIN_FILE=$VCPKG_ROOT/scripts/buildsystems/vcpkg.cmake \
            -DVCPKG_MANIFEST_MODE=ON \
            -DBUILD_EDITOR_QT=OFF \
            -G Ninja

      - name: Build
        shell: bash
        run: |
          cmake --build build --config Release

      - name: List build outputs
        shell: bash
        run: |
          echo "Build outputs:"
          find build -name "*.exe" -o -name "*.dll" -o -name "*.so" -o -name "*.dylib" | head -20

      - name: Run core tests
        shell: bash
        run: |
          cd build
          ctest --output-on-failure --verbose

      - name: Run export_cli to generate test scenes
        if: always()
        shell: bash
        run: |
          echo "============================================================"
          echo "              EXPORT CLI TEST SCENE GENERATION             "
          echo "============================================================"
          
          mkdir -p build/exports
          CLI_PATH=""
          if [ -f "build/tools/export_cli" ]; then
            CLI_PATH="build/tools/export_cli"
          elif [ -f "build/tools/Release/export_cli.exe" ]; then
            CLI_PATH="build/tools/Release/export_cli.exe"
          elif [ -f "build/tools/Debug/export_cli.exe" ]; then
            CLI_PATH="build/tools/Debug/export_cli.exe"
          else
            echo "[ERROR] export_cli not found in expected locations"
            find build -name "*export_cli*" -type f
            exit 1
          fi
          
          echo "[CLI] Using: $CLI_PATH"
          
          # Test predefined scenes
          SCENES="sample holes multi units complex"
          for SCENE in $SCENES; do
            echo ""
            echo "[EXPORT] Generating scene: $SCENE"
            "$CLI_PATH" --out build/exports --scene "$SCENE" || echo "[WARN] Failed to generate $SCENE"
          done
          
          # Test spec-based scene
          if [ -f "tools/specs/scene_complex_spec.json" ]; then
            echo ""
            echo "[EXPORT] Generating from spec: scene_complex_spec.json"
            "$CLI_PATH" --out build/exports --spec tools/specs/scene_complex_spec.json || echo "[WARN] Failed to generate from spec"
          fi
          
          echo ""
          echo "[RESULT] Generated scenes:"
          ls -la build/exports/ || echo "[INFO] No exports directory created"

      - name: Validate sample export (if present)
        if: always()
        shell: bash
        run: |
          echo "============================================================"
          echo "                SAMPLE EXPORT VALIDATION                   "
          echo "============================================================"
          
          # Ensure jsonschema is available (strict requirement for schema validation)
          echo "[SETUP] Ensuring jsonschema is installed"
          python3 -m pip install --user --upgrade pip >/dev/null 2>&1 || true
          python3 -m pip install --user jsonschema >/dev/null 2>&1 || true
          
          # Check if validation script exists
          if [ ! -f "tools/validate_export.py" ]; then
            echo "[ERROR] validate_export.py not found"
            exit 1
          fi
          
          # Find sample export directories
          SCENE_DIRS=""
          if [ -d "sample_exports" ]; then
            SCENE_DIRS="$(find sample_exports -maxdepth 1 -type d -name "scene_*" | sort)"
          fi
          
          if [ -z "$SCENE_DIRS" ]; then
            echo "[SKIP] No sample export directories found"
            exit 0
          fi
          
          echo "============================================================"
          echo "                    VALIDATION SUMMARY                      "
          echo "============================================================"
          
          # Validate each scene directory and collect results
          VALIDATION_FAILED=false
          PASSED_COUNT=0
          FAILED_COUNT=0
          FAILED_SCENES=""
          
          STATS_FILE="consistency_stats.txt"
          : > "$STATS_FILE"
          for SCENE in $SCENE_DIRS; do
            SCENE_NAME=$(basename "$SCENE")
            echo ""
            echo "[VALIDATE] Scene: $SCENE_NAME"
            echo "------------------------------------------------------------"
            
            # Run validation with schema and append stats for consistency report
            if python3 tools/validate_export.py "$SCENE" --schema --stats-out "$STATS_FILE"; then
              echo "[RESULT] $SCENE_NAME: PASSED"
              PASSED_COUNT=$((PASSED_COUNT + 1))
            else
              echo "[RESULT] $SCENE_NAME: FAILED"
              FAILED_COUNT=$((FAILED_COUNT + 1))
              FAILED_SCENES="$FAILED_SCENES $SCENE_NAME"
              VALIDATION_FAILED=true
            fi
          done
          
          echo ""
          echo "============================================================"
          echo "                    VALIDATION SUMMARY                      "
          echo "============================================================"
          echo "[STATS] Total: $((PASSED_COUNT + FAILED_COUNT)) | Passed: $PASSED_COUNT | Failed: $FAILED_COUNT"
          
          if [ "$VALIDATION_FAILED" = true ]; then
            echo "[FAILED] The following scenes failed validation:$FAILED_SCENES"
            echo ""
            echo "[RESULT] VALIDATION FAILED"
            echo "============================================================"
            exit 1
          else
            echo ""
            echo "[RESULT] ALL VALIDATIONS PASSED"
            echo "============================================================"
          fi

      - name: Compare CLI exports with samples (structure check)
        if: always()
        shell: bash
        run: |
          echo "============================================================"
          echo "           STRUCTURE COMPARISON (LOOSE MODE)                "
          echo "============================================================"
          
          # Skip if no exports generated
          if [ ! -d "build/exports" ]; then
            echo "[SKIP] No CLI exports found to compare"
            exit 0
          fi
          
          # Map CLI output names to sample directory names
          declare -A SCENE_MAP
          SCENE_MAP["scene_cli_sample"]="scene_sample"
          SCENE_MAP["scene_cli_holes"]="scene_holes"
          SCENE_MAP["scene_cli_multi"]="scene_multi_groups"
          SCENE_MAP["scene_cli_units"]="scene_units"
          SCENE_MAP["scene_cli_complex"]="scene_complex"
          SCENE_MAP["scene_cli_scene_complex_spec"]="scene_complex"
          
          COMPARISON_FAILED=false
          for CLI_DIR in build/exports/scene_cli_*; do
            [ ! -d "$CLI_DIR" ] && continue
            
            CLI_NAME=$(basename "$CLI_DIR")
            SAMPLE_NAME="${SCENE_MAP[$CLI_NAME]}"
            
            if [ -z "$SAMPLE_NAME" ]; then
              echo "[SKIP] No mapping for $CLI_NAME"
              continue
            fi
            
            SAMPLE_DIR="sample_exports/$SAMPLE_NAME"
            
            echo ""
            echo "[COMPARE] $CLI_NAME -> $SAMPLE_NAME"
            echo "  CLI:    $CLI_DIR"
            echo "  Sample: $SAMPLE_DIR"
            
            if [ ! -d "$SAMPLE_DIR" ]; then
              echo "  [SKIP] Sample directory not found"
              continue
            fi
            
            # Run structure comparison
            if python3 tools/compare_export_to_sample.py "$CLI_DIR" "$SAMPLE_DIR"; then
              echo "  [RESULT] Structure match: PASS"
            else
              echo "  [RESULT] Structure match: FAIL"
              # Strong comparison for critical scenes
              if [ "$CLI_NAME" = "scene_cli_sample" ] || [ "$CLI_NAME" = "scene_cli_holes" ] || [ "$CLI_NAME" = "scene_cli_complex" ] || [ "$CLI_NAME" = "scene_cli_scene_complex_spec" ]; then
                echo "  [ERROR] Required scenes (sample/holes/complex/spec) must match structure exactly!"
                COMPARISON_FAILED=true
              else
                echo "  [INFO] Structure difference allowed for $CLI_NAME (non-critical)"
              fi
            fi
          done
          
          # Exit with error if required comparisons failed
          if [ "$COMPARISON_FAILED" = true ]; then
            echo "[FAILURE] CI failed due to required scene structure mismatches"
            exit 1
          else
            exit 0
          fi

      - name: Field-level comparison (strict for critical scenes)
        if: always()
        shell: bash
        run: |
          echo "============================================================" > field_compare_report.txt
          echo "       FIELD-LEVEL COMPARISON (STRICT NUMERIC)              " >> field_compare_report.txt
          echo "============================================================" >> field_compare_report.txt

          if ! command -v python3 &> /dev/null; then
            echo "[SKIP] Python3 not found, skipping field-level comparison" | tee -a field_compare_report.txt
            exit 0
          fi

          FAIL=false
          RTOL="${FIELD_COMPARE_RTOL:-1e-6}"
          echo "Tolerance (rtol): $RTOL" | tee -a field_compare_report.txt
          
          # Critical scenes requiring strict comparison
          declare -a PAIRS_STRICT
          PAIRS_STRICT+=("build/exports/scene_cli_sample sample_exports/scene_sample")
          PAIRS_STRICT+=("build/exports/scene_cli_holes sample_exports/scene_holes")
          PAIRS_STRICT+=("build/exports/scene_cli_complex sample_exports/scene_complex")
          PAIRS_STRICT+=("build/exports/scene_cli_scene_complex_spec sample_exports/scene_complex")

          # Non-critical scenes with loose comparison
          declare -a PAIRS_LOOSE_UNITS
          PAIRS_LOOSE_UNITS+=("build/exports/scene_cli_units sample_exports/scene_units")
          declare -a PAIRS_LOOSE_MULTI
          PAIRS_LOOSE_MULTI+=("build/exports/scene_cli_multi sample_exports/scene_multi_groups")

          mkdir -p field_reports
          
          # Strict comparison for critical scenes
          for ENTRY in "${PAIRS_STRICT[@]}"; do
            L=$(echo "$ENTRY" | awk '{print $1}')
            R=$(echo "$ENTRY" | awk '{print $2}')
            echo "" >> field_compare_report.txt
            echo "[CHECK] $L  vs  $R" | tee -a field_compare_report.txt
            if [ -d "$L" ] && [ -d "$R" ]; then
              OUT_JSON="field_reports/$(basename "$L")__vs__$(basename "$R").json"
              if python3 tools/compare_fields.py "$L" "$R" --rtol "$RTOL" --json-out "$OUT_JSON" --meta-mode on >> field_compare_report.txt 2>&1; then
                echo "[RESULT] PASS" | tee -a field_compare_report.txt
              else
                echo "[RESULT] FAIL" | tee -a field_compare_report.txt
                FAIL=true
              fi
            else
              echo "[SKIP] One or both scenes missing" | tee -a field_compare_report.txt
            fi
          done

          # Loose comparison for units scenes
          for ENTRY in "${PAIRS_LOOSE_UNITS[@]}"; do
            L=$(echo "$ENTRY" | awk '{print $1}')
            R=$(echo "$ENTRY" | awk '{print $2}')
            echo "" >> field_compare_report.txt
            echo "[CHECK-LOOSE (units)] $L  vs  $R" | tee -a field_compare_report.txt
            if [ -d "$L" ] && [ -d "$R" ]; then
              OUT_JSON="field_reports/$(basename "$L")__vs__$(basename "$R").json"
              if python3 tools/compare_fields.py "$L" "$R" --rtol "$RTOL" --json-out "$OUT_JSON" --allow-gltf-mismatch --mode counts-only --meta-mode on >> field_compare_report.txt 2>&1; then
                echo "[RESULT] PASS (units loose)" | tee -a field_compare_report.txt
              else
                echo "[RESULT] FAIL (units loose)" | tee -a field_compare_report.txt
                FAIL=true
              fi
            else
              echo "[SKIP] One or both scenes missing" | tee -a field_compare_report.txt
            fi
          done

          # Loose comparison for multi scenes
          for ENTRY in "${PAIRS_LOOSE_MULTI[@]}"; do
            L=$(echo "$ENTRY" | awk '{print $1}')
            R=$(echo "$ENTRY" | awk '{print $2}')
            echo "" >> field_compare_report.txt
            echo "[CHECK-LOOSE (multi)] $L  vs  $R" | tee -a field_compare_report.txt
            if [ -d "$L" ] && [ -d "$R" ]; then
              OUT_JSON="field_reports/$(basename "$L")__vs__$(basename "$R").json"
              if python3 tools/compare_fields.py "$L" "$R" --rtol "$RTOL" --json-out "$OUT_JSON" --allow-gltf-mismatch --mode counts-only --meta-mode on >> field_compare_report.txt 2>&1; then
                echo "[RESULT] PASS (multi loose)" | tee -a field_compare_report.txt
              else
                echo "[RESULT] FAIL (multi loose)" | tee -a field_compare_report.txt
                FAIL=true
              fi
            else
              echo "[SKIP] One or both scenes missing" | tee -a field_compare_report.txt
            fi
          done

          if [ "$FAIL" = true ]; then
            echo "[FAILURE] Field-level comparison failed" | tee -a field_compare_report.txt
            exit 1
          else
            echo "[SUCCESS] Field-level comparison passed" | tee -a field_compare_report.txt
          fi

      - name: Generate JSON Schema validation report
        if: always()
        shell: bash
        run: |
          echo "============================================================" > schema_report.txt
          echo "            JSON SCHEMA VALIDATION REPORT                    " >> schema_report.txt
          echo "============================================================" >> schema_report.txt
          echo "# JSON Schema Validation (export_group.schema.json)" > schema_report_full.txt
          echo "" >> schema_report_full.txt

          # Ensure Python and jsonschema
          if ! command -v python3 &> /dev/null; then
            echo "[SKIP] Python3 not found, skipping schema report" | tee -a schema_report.txt
            exit 0
          fi
          python3 -m pip install --user --upgrade pip >/dev/null 2>&1 || true
          python3 -m pip install --user jsonschema >/dev/null 2>&1 || true

          SCHEMA_PATH="docs/schemas/export_group.schema.json"
          if [ ! -f "$SCHEMA_PATH" ]; then
            echo "[SKIP] Schema file not found: $SCHEMA_PATH" | tee -a schema_report.txt
            exit 0
          fi

          # Find scene directories
          SCENE_DIRS=""
          if [ -d "sample_exports" ]; then
            SCENE_DIRS="$(find sample_exports -maxdepth 1 -type d -name "scene_*" | sort)"
          fi

          if [ -z "$SCENE_DIRS" ]; then
            echo "[SKIP] No scene directories found" | tee -a schema_report.txt
            exit 0
          fi

          TOTAL=0
          PASS=0
          FAIL=0
          for SCENE in $SCENE_DIRS; do
            [ -z "$SCENE" ] && continue
            echo "\n[SCHEMA] Scene: $(basename "$SCENE")" | tee -a schema_report_full.txt
            echo "Scene $(basename "$SCENE"):" >> schema_report.txt
            SHAD=0; SPASS=0; SFAIL=0
            for J in "$SCENE"/group_*.json; do
              [ ! -f "$J" ] && continue
              TOTAL=$((TOTAL+1)); SHAD=1
              python3 - "$J" << 'PY' 2>> schema_report_full.txt
import json, sys
from pathlib import Path
import jsonschema
schema_path = Path('docs/schemas/export_group.schema.json')
schema = json.load(open(schema_path, 'r'))
path = Path(sys.argv[1])
data = json.load(open(path, 'r'))
try:
    jsonschema.validate(instance=data, schema=schema)
    print(f"[PASS] {path}")
    sys.exit(0)
except Exception as e:
    print(f"[FAIL] {path}: {e}")
    sys.exit(1)
PY
              if [ $? -eq 0 ]; then
                echo "  - $(basename "$J"): PASS" >> schema_report.txt
                PASS=$((PASS+1)); SPASS=$((SPASS+1))
              else
                echo "  - $(basename "$J"): FAIL" >> schema_report.txt
                FAIL=$((FAIL+1)); SFAIL=$((SFAIL+1))
              fi
            done
            if [ $SHAD -eq 0 ]; then
              echo "  (no group_*.json files)" >> schema_report.txt
            else
              echo "  Scene summary: PASS=$SPASS FAIL=$SFAIL" >> schema_report.txt
            fi
          done

          echo "" >> schema_report.txt
          echo "============================================================" >> schema_report.txt
          echo "TOTAL JSON files: $TOTAL | PASS: $PASS | FAIL: $FAIL" >> schema_report.txt
          echo "============================================================" >> schema_report.txt

      - name: Generate test report
        if: always()
        shell: bash
        run: |
          echo "## Test Report - ${{ matrix.os }}" > test_report.md
          echo "" >> test_report.md
          echo "### Build Configuration" >> test_report.md
          if [ -f "build/CMakeCache.txt" ] && grep -q "earcut\|clipper" build/CMakeCache.txt; then
            echo "- vcpkg: ✅ Success" >> test_report.md
          else
            echo "- vcpkg: ⚠️ Fallback (no vcpkg)" >> test_report.md
          fi
          echo "" >> test_report.md
          echo "### Test Results" >> test_report.md
          echo "- Tests executed successfully" >> test_report.md

          # Add consistency stats if available
          if [ -f "consistency_stats.txt" ]; then
            echo "" >> test_report.md
            echo "### Consistency Stats" >> test_report.md
            echo '```' >> test_report.md
            cat consistency_stats.txt >> test_report.md
            echo '```' >> test_report.md
          fi

          # Add field comparison summary if available
          if [ -f "field_compare_report.txt" ]; then
            echo "" >> test_report.md
            echo "### Field-level Comparison Summary" >> test_report.md
            echo '```' >> test_report.md
            tail -n 50 field_compare_report.txt >> test_report.md || cat field_compare_report.txt >> test_report.md
            echo '```' >> test_report.md
          fi

          # Add field JSON reports overview if available
          if [ -d "field_reports" ]; then
            echo "" >> test_report.md
            echo "### Field-level JSON Report Overview" >> test_report.md
            python3 - "$PWD/field_reports" << 'PY' >> test_report.md
import sys, json
from pathlib import Path
root = Path(sys.argv[1])
files = sorted(root.glob('*.json'))
print('')
if not files:
    print('(no field JSON reports)')
else:
    print('| Pair | Status | Errors |')
    print('|------|--------|--------|')
    for fp in files:
        try:
            d = json.load(open(fp,'r'))
            left = Path(d.get('left','')).name or fp.name.split('__vs__')[0]
            right = Path(d.get('right','')).name or fp.name.split('__vs__')[1]
            status = d.get('status','unknown')
            err_cnt = len(d.get('errors',[]))
            print(f'| {left} vs {right} | {status} | {err_cnt} |')
        except Exception as ex:
            print(f'| {fp.name} | error | 1 |')
PY
          fi
          
      - name: Upload test report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-report-strict-${{ runner.os }}
          path: test_report.md

      - name: Upload schema validation report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: schema-report-${{ runner.os }}
          path: |
            schema_report.txt
            schema_report_full.txt

      - name: Upload field comparison report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: field-compare-report-${{ runner.os }}
          path: |
            field_compare_report.txt
            field_reports/*.json

      - name: Show CMake logs
        if: always()
        shell: bash
        run: |
          echo "=== CMake Configuration Log ==="
          if [ -f build/CMakeFiles/CMakeOutput.log ]; then
            tail -50 build/CMakeFiles/CMakeOutput.log
          fi
          if [ -f build/CMakeFiles/CMakeError.log ]; then
            echo "=== CMake Error Log ==="
            cat build/CMakeFiles/CMakeError.log
          fi

      - name: Upload build logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: build-logs-strict-${{ runner.os }}
          path: |
            build/CMakeFiles/CMakeOutput.log
            build/CMakeFiles/CMakeError.log
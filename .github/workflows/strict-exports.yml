name: Core Strict - Exports, Validation, Comparison

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      rtol:
        description: 'Field comparison rtol (e.g., 1e-6 for Linux/macOS, 1e-5 for Windows)'
        required: false
        default: '1e-6'
      use_vcpkg:
        description: 'Use vcpkg toolchain and cache (slower, full deps)'
        required: false
        default: 'false'

jobs:
  exports-validate-compare:
    runs-on: ubuntu-latest
    concurrency:
      group: core-strict-exports-${{ github.ref }}
      cancel-in-progress: true

    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
          cache: 'pip'
          cache-dependency-path: requirements-ci.txt

      - name: Cache vcpkg
        if: github.event.inputs.use_vcpkg == 'true'
        uses: actions/cache@v3
        with:
          path: |
            C:\vcpkg\installed
            C:\vcpkg\packages
            ~/vcpkg/installed
            ~/vcpkg/packages
            ~/.cache/vcpkg
            ~/AppData/Local/vcpkg/archives
          key: ${{ runner.os }}-vcpkg-${{ hashFiles('**/vcpkg.json') }}-v3
          restore-keys: ${{ runner.os }}-vcpkg-

      - name: Setup vcpkg
        if: github.event.inputs.use_vcpkg == 'true'
        shell: bash
        run: |
          echo "VCPKG_BINARY_SOURCES=clear;default" >> $GITHUB_ENV
          if [ "${{ runner.os }}" == "Windows" ]; then VCPKG_DIR="C:/vcpkg"; else VCPKG_DIR="$HOME/vcpkg"; fi
          if [ -d "$VCPKG_DIR/.git" ]; then (cd "$VCPKG_DIR" && git pull); else rm -rf "$VCPKG_DIR" && git clone https://github.com/Microsoft/vcpkg.git "$VCPKG_DIR"; fi
          # Pin vcpkg to a known-good commit
          (cd "$VCPKG_DIR" && git checkout c9fa965c2a1b1334469b4539063f3ce95383653c)
          if [ "${{ runner.os }}" == "Windows" ]; then (cd "$VCPKG_DIR" && ./bootstrap-vcpkg.bat -disableMetrics); else (cd "$VCPKG_DIR" && ./bootstrap-vcpkg.sh -disableMetrics); fi
          echo "VCPKG_ROOT=$VCPKG_DIR" >> $GITHUB_ENV
          echo "$VCPKG_DIR" >> $GITHUB_PATH

      - name: OS deps
        if: runner.os == 'Linux'
        run: |
          sudo apt-get update
          sudo apt-get install -y cmake ninja-build build-essential
          python -m pip install --upgrade pip
          python -m pip install -r requirements-ci.txt

      - name: Configure
        shell: bash
        run: |
          echo "use_vcpkg=${{ github.event.inputs.use_vcpkg }}"
          if [ "${{ github.event.inputs.use_vcpkg }}" == "true" ]; then
            TOOLCHAIN="$VCPKG_ROOT/scripts/buildsystems/vcpkg.cmake"
            cmake -S . -B build -DCMAKE_TOOLCHAIN_FILE="$TOOLCHAIN" -DCMAKE_BUILD_TYPE=Release -DBUILD_EDITOR_QT=OFF -DCADGF_USE_NLOHMANN_JSON=ON -DCADGF_SORT_RINGS=ON
          else
            cmake -S . -B build -DCMAKE_BUILD_TYPE=Release -DBUILD_EDITOR_QT=OFF -DCADGF_USE_NLOHMANN_JSON=ON -DCADGF_SORT_RINGS=ON -G Ninja
          fi

      - name: Check vendored nlohmann/json header (hard check)
        shell: bash
        run: |
          HDR="tools/third_party/json.hpp"
          if [ -f "$HDR" ]; then
            if grep -q "NLOHMANN_JSON_VERSION_" "$HDR"; then
              echo "[OK] Detected nlohmann/json header with version macros"
              grep -E "#define NLOHMANN_JSON_VERSION_(MAJOR|MINOR|PATCH)" -m3 "$HDR" || true
            else
              echo "::error ::tools/third_party/json.hpp does not appear to be the official nlohmann/json single-header."
              echo "       Replace this file with the upstream json.hpp to enable full parser."
              exit 1
            fi
          else
            echo "::error ::tools/third_party/json.hpp not found. Please vendor the official nlohmann/json.hpp as json.hpp."
            exit 1
          fi

      - name: Build export_cli
        shell: bash
        run: |
          # Try to download prebuilt export_cli from build workflow
          echo "Attempting to download built tools artifact..."
          gh --version >/dev/null 2>&1 || echo "GitHub CLI not available; skipping"
          if command -v gh >/dev/null 2>&1; then
            echo "(Optional) Download via gh is not configured in CI token; skipping"
          fi
          # Fallback to local build
          # Capture vcpkg output if using vcpkg
          if [ "${{ github.event.inputs.use_vcpkg }}" == "true" ]; then
            cmake --build build --config Release --target export_cli --parallel 2 2>&1 | tee build/vcpkg_build.log || cmake --build build --config Release --parallel 2 2>&1 | tee build/vcpkg_build.log
          else
            cmake --build build --config Release --target export_cli --parallel 2 || cmake --build build --config Release --parallel 2
          fi

      - name: Build spec parsing test
        shell: bash
        run: |
          cmake --build build --config Release --target test_spec_parsing --parallel 2 || true

      - name: Build C++ normalization test
        shell: bash
        run: |
          cmake --build build --config Release --target test_normalization_cpp --parallel 2 || true

      - name: Build meta.normalize test
        shell: bash
        run: |
          cmake --build build --config Release --target test_meta_normalize --parallel 2 || true

      - name: Locate export_cli
        id: findcli
        shell: bash
        run: |
          set -e
          CAND=(
            "build/bin/export_cli"
            "build/bin/export_cli.exe"
            "build/tools/export_cli"
            "build/tools/Release/export_cli.exe"
            "build/Release/export_cli"
            "build/Release/export_cli.exe"
          )
          for p in "${CAND[@]}"; do
            if [ -f "$p" ]; then echo "path=$p" >> $GITHUB_OUTPUT; exit 0; fi
          done
          echo "::error::export_cli not found"; exit 1

      - name: Generate scenes via export_cli
        shell: bash
        run: |
          EXPORT_CLI="${{ steps.findcli.outputs.path }}"
          for SCENE in sample holes multi units complex; do
            # Unified full topology for glTF (outer + holes)
            "$EXPORT_CLI" --out build/exports --scene "$SCENE" --gltf-holes full
          done
          [[ -f tools/specs/scene_complex_spec.json ]] && "$EXPORT_CLI" --out build/exports --spec tools/specs/scene_complex_spec.json --gltf-holes full
          [[ -f tools/specs/scene_concave_spec.json ]] && "$EXPORT_CLI" --out build/exports --spec tools/specs/scene_concave_spec.json --gltf-holes full
          [[ -f tools/specs/scene_nested_holes_spec.json ]] && "$EXPORT_CLI" --out build/exports --spec tools/specs/scene_nested_holes_spec.json --gltf-holes full

      - name: Validate scenes (schema + stats)
        shell: bash
        run: |
          python3 -m pip install --user --upgrade pip >/dev/null 2>&1 || true
          # Cache pip
          PIP_DIR="$HOME/.cache/pip"
          mkdir -p "$PIP_DIR"
          python3 -m pip install --user jsonschema >/dev/null 2>&1 || true
          STATS_FILE=consistency_stats.txt
          : > "$STATS_FILE"
          for d in build/exports/scene_cli_*; do
            [ -d "$d" ] || continue
            python3 tools/validate_export.py "$d" --schema --stats-out "$STATS_FILE"
          done
          echo "# Strict Exports Validation Report" > test_report.md
          echo "" >> test_report.md
          echo "## Consistency Stats" >> test_report.md
          echo '```' >> test_report.md
          cat "$STATS_FILE" >> test_report.md
          echo '```' >> test_report.md

      - name: Normalization checks
        shell: bash
        run: |
          echo "Running normalization checks (orientation/start/sortRings)"
          python3 tools/test_normalization.py build/exports

      - name: Validate spec JSONs against schema
        shell: bash
        run: |
          if ls tools/specs/*_spec.json >/dev/null 2>&1; then
            echo "Validating spec JSON files against docs/schemas/cli_spec.schema.json"
            python3 - << 'EOF'
          import json, glob, sys
          from pathlib import Path
          try:
              import jsonschema
          except ImportError:
              print('jsonschema not installed; skipping spec schema validation')
              sys.exit(0)
          schema = json.load(open('docs/schemas/cli_spec.schema.json','r'))
          failed = False
          for p in glob.glob('tools/specs/*_spec.json'):
              data = json.load(open(p,'r'))
              try:
                  jsonschema.validate(instance=data, schema=schema)
                  print('[OK]', p)
              except Exception as e:
                  print('[FAIL]', p, e)
                  failed = True
          sys.exit(1 if failed else 0)
          EOF
          else
            echo "No spec JSON files found under tools/specs"
          fi

      - name: Structure comparison (strong selected)
        shell: bash
        run: |
          set -e
          declare -A MAP
          MAP["scene_cli_sample"]=scene_sample
          MAP["scene_cli_holes"]=scene_holes
          MAP["scene_cli_multi"]=scene_multi_groups
          MAP["scene_cli_units"]=scene_units
          MAP["scene_cli_complex"]=scene_complex
          MAP["scene_cli_scene_complex_spec"]=scene_complex
          MAP["scene_cli_scene_concave_spec"]=scene_concave
          MAP["scene_cli_scene_nested_holes_spec"]=scene_nested_holes
          COMPARISON_FAILED=false
          for L in build/exports/scene_cli_*; do
            [ -d "$L" ] || continue
            NAME=$(basename "$L")
            R="sample_exports/${MAP[$NAME]}"
            [ -d "$R" ] || continue
            if python3 tools/compare_export_to_sample.py "$L" "$R"; then
              echo "[OK] $NAME structure matches"
            else
              if [ "$NAME" = "scene_cli_sample" ] || [ "$NAME" = "scene_cli_holes" ] || [ "$NAME" = "scene_cli_complex" ] || [ "$NAME" = "scene_cli_scene_complex_spec" ] || [ "$NAME" = "scene_cli_scene_concave_spec" ] || [ "$NAME" = "scene_cli_scene_nested_holes_spec" ]; then
                echo "::error::$NAME must match structure exactly"
                COMPARISON_FAILED=true
              else
                echo "[WARN] $NAME structural diffs allowed"
              fi
            fi
          done
          if [ "$COMPARISON_FAILED" = true ]; then exit 1; fi

      - name: Field-level comparison (strict)
        shell: bash
        env:
          FIELD_COMPARE_RTOL: ${{ github.event.inputs.rtol || '1e-6' }}
        run: |
          RTOL="${FIELD_COMPARE_RTOL:-1e-6}"
          # Adjust tolerance for Windows floating point precision differences
          if [ "${{ runner.os }}" == "Windows" ] && [ "$RTOL" == "1e-6" ]; then
            RTOL="1e-5"
            echo "Adjusted rtol to $RTOL for Windows platform"
          fi
          echo "rtol=$RTOL" >> $GITHUB_OUTPUT
          python3 tools/compare_fields.py build/exports/scene_cli_sample sample_exports/scene_sample --rtol "$RTOL" --json-out field_sample.json --meta-mode on --mode full
          python3 tools/compare_fields.py build/exports/scene_cli_holes sample_exports/scene_holes --rtol "$RTOL" --json-out field_holes.json --meta-mode on --mode full
          python3 tools/compare_fields.py build/exports/scene_cli_complex sample_exports/scene_complex --rtol "$RTOL" --json-out field_complex.json --meta-mode on --mode full
          python3 tools/compare_fields.py build/exports/scene_cli_scene_complex_spec sample_exports/scene_complex --rtol "$RTOL" --json-out field_spec_complex.json --meta-mode on --mode full
          python3 tools/compare_fields.py build/exports/scene_cli_units sample_exports/scene_units --rtol "$RTOL" --json-out field_units.json --mode full --meta-mode on --allow-gltf-mismatch
          # Upgrade concave/nested_holes to full mode comparisons as well
          # Map spec-generated scenes to their golden folders
          python3 tools/compare_fields.py build/exports/scene_cli_scene_concave_spec sample_exports/scene_concave --rtol "$RTOL" --json-out field_concave.json --mode full --meta-mode on --allow-gltf-mismatch
          python3 tools/compare_fields.py build/exports/scene_cli_scene_nested_holes_spec sample_exports/scene_nested_holes --rtol "$RTOL" --json-out field_nested_holes.json --mode full --meta-mode on --allow-gltf-mismatch
          python3 tools/compare_fields.py build/exports/scene_cli_multi sample_exports/scene_multi_groups --rtol "$RTOL" --json-out field_multi.json --mode full --meta-mode on --allow-gltf-mismatch

      - name: Run spec parsing smoke test
        shell: bash
        run: |
          echo "Running spec parsing smoke test"
          if [ -f "build/tests/tools/test_spec_parsing" ]; then
            build/tests/tools/test_spec_parsing
          elif [ -f "build/tests/tools/Release/test_spec_parsing.exe" ]; then
            build/tests/tools/Release/test_spec_parsing.exe
          else
            echo "[WARN] test_spec_parsing not found (build config/platform)"
          fi

      - name: Run C++ normalization checks
        shell: bash
        run: |
          echo "Running C++ normalization checks"
          if [ -f "build/tests/tools/test_normalization_cpp" ]; then
            build/tests/tools/test_normalization_cpp
          elif [ -f "build/tests/tools/Release/test_normalization_cpp.exe" ]; then
            build/tests/tools/Release/test_normalization_cpp.exe
          else
            echo "[WARN] test_normalization_cpp not found (build config/platform)"
          fi

      - name: Run meta.normalize emission test
        shell: bash
        run: |
          echo "Running meta.normalize emission test"
          if [ -f "build/tests/tools/test_meta_normalize" ]; then
            build/tests/tools/test_meta_normalize
          elif [ -f "build/tests/tools/Release/test_meta_normalize.exe" ]; then
            build/tests/tools/Release/test_meta_normalize.exe
          else
            echo "[WARN] test_meta_normalize not found (build config/platform)"
          fi

      - name: Generate vcpkg cache statistics
        if: github.event.inputs.use_vcpkg == 'true'
        shell: bash
        run: |
          echo "Generating vcpkg cache statistics..."
          mkdir -p build

          # Initialize counters
          RESTORED=0
          INSTALLING=0

          # Check if vcpkg build log exists
          if [ -f "build/vcpkg_build.log" ]; then
            # Count restored packages (packages fetched from cache)
            RESTORED=$(grep -c "Restored" build/vcpkg_build.log 2>/dev/null || echo "0")
            # Count installing packages (packages built from source)
            INSTALLING=$(grep -c "Building" build/vcpkg_build.log 2>/dev/null || echo "0")
          fi

          # If no specific patterns found, check for vcpkg general activity
          if [ "$RESTORED" -eq "0" ] && [ "$INSTALLING" -eq "0" ]; then
            # Try alternative patterns
            if [ -f "build/vcpkg_build.log" ]; then
              RESTORED=$(grep -cE "(from cache|cached)" build/vcpkg_build.log 2>/dev/null || echo "0")
              INSTALLING=$(grep -cE "(Extracting|Building|Installing)" build/vcpkg_build.log 2>/dev/null || echo "0")
            fi
          fi

          # Calculate hit rate
          TOTAL=$((RESTORED + INSTALLING))
          if [ "$TOTAL" -gt 0 ]; then
            HIT_RATE=$((RESTORED * 100 / TOTAL))
          else
            # Default to 0 if no packages detected
            HIT_RATE=0
          fi

          # Generate JSON statistics file
          cat > build/vcpkg_cache_stats.json << EOF
          {
            "hit_rate": $HIT_RATE,
            "restored": $RESTORED,
            "installing": $INSTALLING,
            "total": $TOTAL,
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "use_vcpkg": true
          }
          EOF

          echo "Cache statistics generated:"
          cat build/vcpkg_cache_stats.json

      - name: Upload reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: strict-exports-reports-${{ runner.os }}
          path: |
            test_report.md
            consistency_stats.txt
            field_*.json
            build/vcpkg_cache_stats.json
            build/vcpkg_build.log

      - name: Failure guidance
        if: failure()
        shell: bash
        run: |
          echo "::group::Guidance for fixing CI failures"
          echo "1) Run local CI to reproduce:" 
          echo "   bash tools/local_ci.sh --build-type Release --rtol 1e-6 --gltf-holes full"
          echo "2) Check README Contributing / PR Checklist and docs/Troubleshooting.md"
          echo "   - Ensure normalization (orientation/start) and schema checks pass"
          echo "   - Refresh golden samples if outputs changed: tools/refresh_golden_samples.sh"
          echo "   - For JSON spec: use official nlohmann/json header and -DCADGF_USE_NLOHMANN_JSON=ON"
          echo "3) Inspect uploaded artifacts (field_*.json, consistency_stats.txt)"
          echo "::endgroup::"
